# ğŸš€ Toxic Chat Classifier - Detecting Harmful Content

## ğŸ“Œ Introduction
Toxic Chat Classifier is a machine learning model that leverages **BERT multilingual (`google-bert/bert-base-multilingual-cased`)** to detect toxic content in text messages.  
The system supports **fine-tuning, text prediction**, and a **RESTful API** for easy integration into applications.

---

## ğŸ— **Project Structure**
```bash
toxic-chat-classifier/
â”‚â”€â”€ configs/                     # Configuration files
â”‚   â”œâ”€â”€ config.yaml               # Main config file
â”‚â”€â”€ data/                         # Training dataset
â”‚   â”œâ”€â”€ raw/                      # Raw datasets
â”‚   â”œâ”€â”€ processed/                 # Processed datasets
â”‚   â”œâ”€â”€ dataset_loader.py          # Dataset preprocessing and loading
â”‚â”€â”€ models/                       # Model checkpoints
â”‚   â”œâ”€â”€ pre_trained/               # Pre-trained models
â”‚   â”œâ”€â”€ fine_tuned/                # Fine-tuned models
â”‚â”€â”€ src/                          # Source code
â”‚   â”œâ”€â”€ training/                  # Model fine-tuning scripts
â”‚   â”‚   â”œâ”€â”€ train.py                # Main training script
â”‚   â”‚   â”œâ”€â”€ dataset.py              # Dataset handling
â”‚   â”‚   â”œâ”€â”€ model.py                # Model definition
â”‚   â”‚   â”œâ”€â”€ trainer.py              # Training loop
â”‚   â”œâ”€â”€ inference/                  # Inference scripts
â”‚   â”‚   â”œâ”€â”€ predict.py               # Inference function
â”‚   â”œâ”€â”€ api/                        # FastAPI server for inference
â”‚   â”‚   â”œâ”€â”€ app.py                   # API routes
â”‚â”€â”€ notebooks/                     # Jupyter Notebooks for testing
â”‚   â”œâ”€â”€ data_exploration.ipynb      # Dataset analysis
â”‚   â”œâ”€â”€ model_evaluation.ipynb      # Model evaluation
â”‚â”€â”€ scripts/                       # Utility scripts
â”‚   â”œâ”€â”€ preprocess.py               # Data preprocessing
â”‚   â”œâ”€â”€ evaluate.py                 # Model evaluation
â”‚   â”œâ”€â”€ test_api.py                 # API testing
â”‚â”€â”€ tests/                         # Unit tests
â”‚   â”œâ”€â”€ test_model.py                # Model inference tests
â”‚   â”œâ”€â”€ test_api.py                  # API response tests
â”‚â”€â”€ requirements.txt                # Dependencies
â”‚â”€â”€ Dockerfile                      # Docker container setup
â”‚â”€â”€ README.md                       # Documentation
â”‚â”€â”€ .gitignore                       # Git ignore file
â”‚â”€â”€ setup.py                         # Package installation script
```

---

## âš™ï¸ **Installation**
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/your_username/toxic-chat-classifier.git
cd toxic-chat-classifier
```

### **2ï¸âƒ£ Create a Virtual Environment**
```bash
python3 -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate     # On Windows
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ Download Pre-trained Model (Optional)**
To fine-tune the model, you may need to download **`google-bert/bert-base-multilingual-cased`**:
```bash
from transformers import AutoModel
AutoModel.from_pretrained("google-bert/bert-base-multilingual-cased")
```

---

## ğŸ¯ **Fine-Tuning the Model**
1. **Prepare your dataset** (CSV format with `"text"` and `"label"` columns).
2. **Modify `config.yaml`** in `configs/` with dataset paths.
3. **Run the training script**:
```bash
python src/training/train.py
```

### **ğŸ›  Example Config (`configs/config.yaml`)**
```yaml
model:
  name: "google-bert/bert-base-multilingual-cased"
  num_labels: 2
  cache_dir: "models/"

training:
  batch_size: 16
  num_epochs: 3
  learning_rate: 5e-5
  weight_decay: 0.01
  max_length: 256
  warmup_steps: 500
  save_model_path: "models/fine_tuned/"

data:
  train_file: "data/processed/train.csv"
  val_file: "data/processed/val.csv"
  test_file: "data/processed/test.csv"
```

After fine-tuning, the model will be saved at `models/fine_tuned/`.

---

## ğŸš€ **Running the API**
### **1ï¸âƒ£ Start the API Server**
Run the FastAPI server:
```bash
uvicorn src.api.app:app --host 0.0.0.0 --port 8000 --reload
```

### **2ï¸âƒ£ Test the API**
**Swagger UI (Interactive API Documentation):**
- Open in browser: `http://127.0.0.1:8000/docs`

---

## ğŸ“Œ **Using the API**
### **1ï¸âƒ£ Predict a Single Text**
**Request:**
```bash
curl -X 'POST' \
  'http://127.0.0.1:8000/predict/' \
  -H 'Content-Type: application/json' \
  -d '{
        "text": "You are an idiot!"
      }'
```
**Response:**
```json
{
  "text": "You are an idiot!",
  "label": "toxic",
  "confidence": 0.97
}
```

<!-- ---

## ğŸ³ **Deploying with Docker**
### **1ï¸âƒ£ Build Docker Image**
```bash
docker build -t toxic-chat-classifier .
```

### **2ï¸âƒ£ Run Docker Container**
```bash
docker run -p 8000:8000 toxic-chat-classifier
```
Now the API will be available at `http://127.0.0.1:8000`. -->

<!-- ---

## ğŸ§ª **Running Tests**
To ensure everything works correctly, run unit tests:
```bash
pytest tests/
``` -->

---

## ğŸ“ **Contact**
ğŸ“§ Email: `Chungcgcg@gmail.com`  
